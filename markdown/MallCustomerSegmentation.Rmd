---
title: "Mall Customer Segmentation"
author: "Trevor Okinda"
date: ""
output:
  github_document: 
    toc: yes
    toc_depth: 4
    fig_width: 6
    fig_height: 4
    df_print: default
editor_options:
  chunk_output_type: console
---

# Student Details

|                                              |     |
|----------------------------------------------|-----|
| **Student ID Number**                        | 134780 |
| **Student Name**                             | Trevor Okinda |
| **BBIT 4.2 Group**                           | C |
| **Project Name**                             | Mall Customer Segmentation |

# Setup Chunk

**Note:** the following KnitR options have been set as the global defaults: <BR> `knitr::opts_chunk$set(echo = TRUE, warning = FALSE, eval = TRUE, collapse = FALSE, tidy = TRUE)`.

More KnitR options are documented here <https://bookdown.org/yihui/rmarkdown-cookbook/chunk-options.html> and here <https://yihui.org/knitr/options/>.

```{r setup, include=FALSE}
library(formatR)
knitr::opts_chunk$set(
  warning = FALSE,
  collapse = FALSE
)
```

# Understanding the Dataset (Exploratory Data Analysis (EDA))

## Loading the Dataset

### Source: 

The dataset that was used can be downloaded here: *\<https://www.kaggle.com/datasets/rahulsah06/titanic?resource=download\>*

### Reference:

*\<Avagyan, Z. (2017). Weather CSV [Data set]. Kaggle. https://www.kaggle.com/datasets/zaraavagyan/weathercsv\>\
Refer to the APA 7th edition manual for rules on how to cite datasets: <https://apastyle.apa.org/style-grammar-guidelines/references/examples/data-set-references>*

```{r Load dataset}
#Load Dataset

CustomerData <-read.csv("Customers.csv", colClasses = c(
  CustomerId = "numeric",
  Gender = "factor",
  Age = "numeric",
  Annual_Income = "numeric",
  Spending_Score = "numeric"
))

#View Dataset
View(CustomerData)
```

### Measures of Frequency
```{r}
#Measures of Frequency
# Display the structure of the dataset
str(CustomerData)

# Display summary statistics
summary(CustomerData)

# Frequency table for Gender
gender_frequency <- table(CustomerData$Gender)
print("Frequency table for Gender:")
print(gender_frequency)

# Histogram for Age
hist(CustomerData$Age, main = "Histogram of Age", xlab = "Age")

# Histogram for Annual Income
hist(CustomerData$Annual_Income, main = "Histogram of Annual Income", xlab = "Annual Income")

# Histogram for Spending Score
hist(CustomerData$Spending_Score, main = "Histogram of Spending Score", xlab = "Spending Score")

```

### Measures of relationship
```{r}
#Measures of Central Tendency
# Display mean, median, and mode for Age
mean_age <- mean(CustomerData$Age)
median_age <- median(CustomerData$Age)
mode_age <- names(sort(-table(CustomerData$Age)))[1]

print("Measures of Central Tendency for Age:")
print(paste("Mean:", mean_age))
print(paste("Median:", median_age))
print(paste("Mode:", mode_age))

# Display mean, median, and mode for Annual Income
mean_income <- mean(CustomerData$Annual_Income)
median_income <- median(CustomerData$Annual_Income)
mode_income <- names(sort(-table(CustomerData$Annual_Income)))[1]

print("Measures of Central Tendency for Annual Income:")
print(paste("Mean:", mean_income))
print(paste("Median:", median_income))
print(paste("Mode:", mode_income))

# Display mean, median, and mode for Spending Score
mean_score <- mean(CustomerData$Spending_Score)
median_score <- median(CustomerData$Spending_Score)
mode_score <- names(sort(-table(CustomerData$Spending_Score)))[1]

print("Measures of Central Tendency for Spending Score:")
print(paste("Mean:", mean_score))
print(paste("Median:", median_score))
print(paste("Mode:", mode_score))
```

### Measures of Distribution
```{r}
#Measures of Distribution
# Display range for Age, Annual Income, and Spending Score
age_range <- range(CustomerData$Age)
income_range <- range(CustomerData$Annual_Income)
score_range <- range(CustomerData$Spending_Score)

print("Range for Age:")
print(age_range)

print("Range for Annual Income:")
print(income_range)

print("Range for Spending Score:")
print(score_range)

# Display standard deviation for Age, Annual Income, and Spending Score
sd_age <- sd(CustomerData$Age)
sd_income <- sd(CustomerData$Annual_Income)
sd_score <- sd(CustomerData$Spending_Score)

print("Standard Deviation for Age:")
print(sd_age)

print("Standard Deviation for Annual Income:")
print(sd_income)

print("Standard Deviation for Spending Score:")
print(sd_score)

# Display quantiles for Age, Annual Income, and Spending Score
quantiles_age <- quantile(CustomerData$Age)
quantiles_income <- quantile(CustomerData$Annual_Income)
quantiles_score <- quantile(CustomerData$Spending_Score)

print("Quantiles for Age:")
print(quantiles_age)

print("Quantiles for Annual Income:")
print(quantiles_income)

print("Quantiles for Spending Score:")
print(quantiles_score)
```

### Measures of Relationship
```{r}
#Measures of Relationship
# Display correlation matrix
correlation_matrix <- cor(CustomerData[, c("Age", "Annual_Income", "Spending_Score")])
print("Correlation Matrix:")
print(correlation_matrix)

# Scatter plot matrix
pairs(CustomerData[, c("Age", "Annual_Income", "Spending_Score")], main = "Scatter Plot Matrix")

# Scatter plot between Annual Income and Spending Score
plot(CustomerData$Annual_Income, CustomerData$Spending_Score, main = "Scatter Plot: Annual Income vs Spending Score", 
     xlab = "Annual Income", ylab = "Spending Score", col = as.numeric(CustomerData$Gender))

# Add regression line to the scatter plot
abline(lm(Spending_Score ~ Annual_Income, data = CustomerData), col = "red")

```

### ANOVA
```{r}
#ANOVA
# Perform ANOVA for Age, Annual Income, and Spending Score based on Gender
anova_age <- aov(Age ~ Gender, data = CustomerData)
anova_income <- aov(Annual_Income ~ Gender, data = CustomerData)
anova_score <- aov(Spending_Score ~ Gender, data = CustomerData)

# Display ANOVA results
print("ANOVA for Age:")
print(summary(anova_age))

print("ANOVA for Annual Income:")
print(summary(anova_income))

print("ANOVA for Spending Score:")
print(summary(anova_score))

```

### Univariate Plots
```{r}
#Univariate Plots
# Load the necessary libraries
library(ggplot2)
# Univariate plot for Age - Histogram
ggplot(CustomerData, aes(x = Age)) +
  geom_histogram(binwidth = 5, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Age", x = "Age", y = "Frequency")

# Univariate plot for Annual Income - Boxplot
ggplot(CustomerData, aes(x = 1, y = Annual_Income, fill = Gender)) +
  geom_boxplot() +
  labs(title = "Boxplot of Annual Income", x = "", y = "Annual Income") +
  scale_fill_manual(values = c("pink", "lightblue"))

# Univariate plot for Spending Score - Density Plot
ggplot(CustomerData, aes(x = Spending_Score, fill = Gender)) +
  geom_density(alpha = 0.5) +
  labs(title = "Density Plot of Spending Score", x = "Spending Score", y = "Density") +
  scale_fill_manual(values = c("pink", "lightblue"))
```

### Multivariate Plots
```{r}
#MultiVariate Plots
# Load the necessary libraries
library(ggplot2)

# Multivariate scatter plot matrix
ggplot(CustomerData, aes(x = Age, y = Annual_Income, color = Gender)) +
  geom_point() +
  labs(title = "Scatter Plot Matrix", x = "Age", y = "Annual Income") +
  theme_minimal()

# Multivariate scatter plot for Spending Score vs. Annual Income
ggplot(CustomerData, aes(x = Annual_Income, y = Spending_Score, color = Gender)) +
  geom_point() +
  labs(title = "Scatter Plot: Spending Score vs. Annual Income", x = "Annual Income", y = "Spending Score") +
  theme_minimal()

```

### Check for missingness
```{r}
# Check for missing values
missing_values <- sum(is.na(CustomerData))

# Display confirmation
if (missing_values > 0) {
  print("Missing values are present in the dataset.")
  print(paste("Total missing values: ", missing_values))
  print("Columns with missing values:")
  print(names(CustomerData)[colSums(is.na(CustomerData)) > 0])
} else {
  print("No missing values are present in the dataset.")
}

```

### Data Transformations
```{r}
# Data transformations

# Standardizing numeric variables (Age, Annual_Income, Spending_Score)
numeric_cols <- c("Age", "Annual_Income", "Spending_Score")
CustomerData[numeric_cols] <- scale(CustomerData[numeric_cols])

# Creating a new feature (Age category)
CustomerData$Age_Category <- cut(CustomerData$Age, breaks = c(0, 30, 50, Inf), labels = c("Young", "Middle-aged", "Senior"))

# Display the transformed dataset
head(CustomerData)
```

### Data splitting
```{r}
# Data Splitting
# Install and load the necessary libraries
library(caret)

# Set a seed for reproducibility
set.seed(123)

# Specify the proportion for training and testing sets
split_ratio <- 0.8  # 80% for training, 20% for testing

# Split the data
splitIndex <- createDataPartition(CustomerData$Spending_Score, p = split_ratio, list = FALSE)
train_data <- CustomerData[splitIndex, ]
test_data <- CustomerData[-splitIndex, ]

# Display the dimensions of the split datasets
cat("Training data dimensions:", dim(train_data), "\n")
cat("Testing data dimensions:", dim(test_data), "\n")

```

### Boostrapping
```{r}
#Bootstrapping
# Load the necessary libraries
library(boot)


# Set a seed for reproducibility
set.seed(123)

# Function to calculate the mean of the variable of interest
calculate_mean <- function(data, indices) {
  sample_data <- data[indices, ]
  return(mean(sample_data$Spending_Score))
}

# Number of bootstrap samples
num_boot_samples <- 1000

# Perform bootstrapping
boot_results <- boot(data = CustomerData, statistic = calculate_mean, R = num_boot_samples)

# Display the bootstrap results
print("Bootstrap Results:")
print(boot_results)

# Plot the bootstrap distribution
hist(boot_results$t, main = "Bootstrap Distribution of Mean Spending_Score", xlab = "Mean Spending_Score")

```

### Cross-validation
```{r}
# Load the necessary libraries
install.packages("caret")
library(caret)

# Set a seed for reproducibility
set.seed(123)

# Specify the number of folds for cross-validation
num_folds <- 5

# Create a training control object for cross-validation
train_control <- trainControl(method = "cv", number = num_folds)

# Train a model (linear regression) using cross-validation
model <- train(Spending_Score ~ Age + Annual_Income + Gender, data = CustomerData, method = "lm", trControl = train_control)

# Display the cross-validation results
print("Cross-Validation Results:")
print(model$results)
```

### Model Training
```{r}
# Model Training
# Load the necessary libraries
# install.packages("ggplot2")
library(ggplot2)

# Load the dataset
# Select relevant features for clustering
features <- CustomerData[, c("Annual_Income", "Spending_Score")]

# Set a seed for reproducibility
set.seed(123)

# Determine the optimal number of clusters (K) using the elbow method
wss <- numeric(10)
for (i in 1:10) {
  kmeans_model <- kmeans(features, centers = i, nstart = 10)
  wss[i] <- sum(kmeans_model$withinss)
}

# Plot the elbow curve
plot(1:10, wss, type = "b", pch = 19, frame = FALSE, main = "Elbow Method for Optimal K",
     xlab = "Number of Clusters (K)", ylab = "Within-cluster Sum of Squares (WSS)")

# Determine the optimal K visually (elbow point)
optimal_k <- 3  # Replace with the visually determined optimal K

# Apply K-means clustering with the optimal K
kmeans_model <- kmeans(features, centers = optimal_k, nstart = 10)

# Add cluster information to the original dataset
CustomerData$Cluster <- as.factor(kmeans_model$cluster)

# Plot the clusters
ggplot(CustomerData, aes(x = Annual_Income, y = Spending_Score, color = Cluster)) +
  geom_point() +
  labs(title = "Customer Segmentation", x = "Annual Income", y = "Spending Score") +
  theme_minimal()
```


### Performance Comparison
```{r}
#Performance Comparison
# Load the necessary libraries
library(cluster)  # For k-means clustering
library(dbscan)   # For DBSCAN
library(fpc)      # For silhouette measure



# Set a seed for reproducibility
set.seed(123)

# Select relevant features for clustering
clustering_features <- CustomerData[, c("Annual_Income", "Spending_Score")]

# Specify the number of clusters for k-means
num_clusters <- 3

# Fit the clustering models
kmeans_model <- kmeans(clustering_features, centers = num_clusters)
dbscan_model <- dbscan(clustering_features, eps = 0.5, MinPts = 5)
pam_model <- pam(clustering_features, k = num_clusters)

# Evaluate clustering quality using silhouette width
silhouette_kmeans <- silhouette(kmeans_model$cluster, dist(clustering_features))
silhouette_dbscan <- silhouette(dbscan_model$cluster, dist(clustering_features))
silhouette_pam <- silhouette(pam_model$cluster, dist(clustering_features))

# Print silhouette width for each clustering model
cat("K-means Silhouette Width:", mean(silhouette_kmeans[, 3]), "\n")
cat("DBSCAN Silhouette Width:", mean(silhouette_dbscan[, 3]), "\n")
cat("PAM Silhouette Width:", mean(silhouette_pam[, 3]), "\n")


```


### Saving the Model
```{r}
# Load the necessary libraries
library(cluster)

# Load the dataset
CustomerData <- read.csv("Customers.csv", colClasses = c(
  CustomerId = "numeric",
  Gender = "factor",
  Age = "numeric",
  Annual_Income = "numeric",
  Spending_Score = "numeric"
))

# Set a seed for reproducibility
set.seed(123)

# Select relevant features for clustering
clustering_features <- CustomerData[, c("Annual_Income", "Spending_Score")]

# Specify the number of clusters for k-means
num_clusters <- 5

# Calculate the Euclidean distance matrix
distances <- dist(clustering_features)

# Perform hierarchical clustering
hclust_model <- hclust(distances, method = "ward")

# Save the hclust model and the cut points
saveRDS(hclust_model, "./models/saved_hclust_model.rds")
saveRDS(num_clusters, "./models/saved_hclust_num_clusters.rds")

# Load the saved hclust model and num_clusters
loaded_hclust_model <- readRDS("./models/saved_hclust_model.rds")
loaded_num_clusters <- readRDS("./models/saved_hclust_num_clusters.rds")

# Cut the tree to get k clusters using loaded information
kmeans_clusters <- cutree(loaded_hclust_model, k = loaded_num_clusters)

# Create a new dataframe with cluster assignments
clustered_data <- cbind(CustomerData, Cluster = kmeans_clusters)

# Display the resulting dataframe
print(clustered_data)
```

